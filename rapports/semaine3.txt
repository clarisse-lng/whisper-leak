verif a la main sur 15 exemples les resultats des classifieurs

raconter les essais sur le rapport

refaire le zero shot avec les memes labels que le modele local, labels.json bien pour expliquer le contenu attendu

rapport presque fini pour le 09/03 afin de pouvoir le revoir
- espliquer le sujet (art. whisperleak principalement)
- pq c'est important (sujets imp)
- pas le seul papier sur les fuites de donnees sur llms (mentionner les autres articles)
- tt le tps predire les contenus 
- papiers attaquent pas le chiffrement et seulement ce qui est observable, timing/token avec des exemples
- insister sur les features
- but : reproduire ce qui est fait dans l'article et rendre l'attaque plus credible/realiste
- pistes/choses envisagees pour la suite : 
--> essayer whisperleak avec des suejts plus inte
--> test avec mitigations
--> strategies pour contourner / implementer
- code dispo et dataset dispo et fournis 
- interception du trafic a faire dans la suite
- reprod avec des modeles existants
- comparaison des histogrammes
==> refaire les histogrammes et les comparer dans le rapport 

figures a faire :
- une pour expliquer les echanges (avec les tokens et le decoupage/streaming)
- token (decoupage a expliquer) ==> tokenizer 

mettre en evidence le lien dans la figure avec les tps entre les paquets de token + taille en paquets d'octets
brouiller sur la figure l'échange

clarifier les repeats dans les prompts.json (large1, large2)

llm tres instable par rapport aux entrees (espaces etc assez influents)
impact sur la sortie avec des rajotus d'espace etc

fouiller dans le rep pour trv interets large1 et large2 

claude haiku openrouter pour experiences a plus large echelle pour tester plusieurs modeles (pour explorer plus largement les choses)
fonctionne comme une proxy, implementation differente 

tourner en local avec ollama pour l'instant

whisperleak basé sur API 
interface web a explorer (car plus prompt aux attaques pour un utilisateur lambda)

landchain (?) a regarder pour un autre module de test



------------------------------------

# Compte rendu 23/02/2026

- Refaire l'analyse avec les labels pour s'assurer de que ça soit comparable entre OpenAI et LLM en local
- Débuter à rédiger:
    - C'est pas le seule article qui existe pour des fuites des données
    - Le papier n'attacke pas le chiffrement, repose surtout sur le timing de réponse
    - S'intereser dans les elements de taille variable (inter token delay), screen de tokenizer openAI, car pas évident
    - Parler de la suite du projet: 
        - Essayer whisperleak avec des classes plus differentes, faire attention au realisme
        - Strategies de mitigation proposes.
        - Essayer de reproduire ça en local
        - Dire qu'il a un dataset disponible fourni
    - Faire deux figures, explication d'un token, un example, screenshot de tokenizer sur des differentes examples
        - t0 = ... 
        - t1 = .......
        - ...
        - tn = ...........
        Observer ça.
    - Ça doit etre compris par un informaticien lambda sans experience sur des modeles.
    - Motivation : 
        1. Reproduire attacks déjà faites au passé
        2. Rendre l'attack plus crédible
    
- Question interesante pour après le rapport: Impact sur la sortie de rajout des espaces 
- Regarder la bibliotheque LangChain pour s'abstraire un peu de l'interface OpenAI => Choice: LangChain? OpenAI?
- OpenRouter: Regarder a plus grande echelle (à explorer pour la fin du projet)
- OLLAMA / MISTRAL: Faire pour faire tourner sur un cluster
- Essayer de faire des tests sur des interfaces web vu que les attackes sont censées etre faites à l'utilisateur final: se posser la question des differentes interfaces / logiciels libres (idées)
